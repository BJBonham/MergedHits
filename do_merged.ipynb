{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to run this cell twice or else the following cells won't run.\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from IPython.display import FileLink, FileLinks\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 image has 6x6 pixels = 36 pixels \n",
    "pixels = [\"pixel_{0}\".format(i) for i in range(36)]\n",
    "def to_image(df):\n",
    "    return  np.expand_dims(np.expand_dims(df[pixels], axis=-1).reshape(-1,6,6), axis=-1)\n",
    "\n",
    "# You need to email hichemb@princeton.edu to request access to this directory, or else this line will not work\n",
    "df = pd.read_hdf(\"/eos/user/h/hboucham/SWAN_projects/MergedHits/output_final.h5\", key=\"df\", mode='r') # do not write to this file !\n",
    "\n",
    "# If you want to run \"file.h5\" locally use the following lines:\n",
    "# store_train = pd.HDFStore(\"file.h5\")\n",
    "# df = store_train.select(\"df\" , stop = -1) # df here is like a tree1 in Root\n",
    "\n",
    "#Last Cuts and selections:\n",
    "#cut on DeltaR and nUniqueSimTracksInSharedHit\n",
    "df = df[(df[\"GenDeltaR\"]<0.1) & (df[\"nUniqueSimTracksInSharedHit\"]>-1)]\n",
    "df_old = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing events that have single pixel since the neural network cannot tell whether it's merged or not, there is simply not enough information.\n",
    "pixelColumns = [\"pixel_%i\" % x for x in range(36)]\n",
    "pixels_df = df[pixelColumns].values\n",
    "# This printout is a sanity check, there 36 pixels so we expect pixels_df to have 36 columns\n",
    "#print(pixels_df[0].shape)\n",
    "pixel_number = pixels_df.astype(bool).sum(axis=1)\n",
    "df.insert(0, \"Pixel_number\", pixel_number)\n",
    "# the df.info() printouts allows us to see how many events were removed.\n",
    "#print df.info()\n",
    "df = df[df[\"Pixel_number\"]>1]\n",
    "#print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frac=0.5 sets half training and half testing\n",
    "df_train=df.sample(frac=0.5)\n",
    "df_test=df.drop(df_train.index)\n",
    "images_train = to_image(df_train)\n",
    "images_test = to_image(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: printout (events, variables) Variables include 36 pixels, and a few others you can find using df.info() command\n",
    "print \"Test Data Shape: \",df_test.shape\n",
    "print \"Train Data Shape: \",df_train.shape\n",
    "#print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing a log file for your training, which will be used for the loss vs epoch plot\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('training.txt', separator=\",\", append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the CNN\n",
    "# Adding layers to Neural Network: (1) is convolutional,(1.5) 2D layer ,(2) flatten output then feed it to (3) which is a regular neural network.\n",
    "# (4) drops nodes in NN to avoid overfitting, finallly (5) outputs 2 values (prob(notmergedhit), prob(merged hit)), must add up to 1.\n",
    "\n",
    "# Define the network\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#layer (1)\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(4,4), padding='same', activation='relu'))\n",
    "\n",
    "#layer (1.5) : you can play with these layers individually or together until you find the best combination \n",
    "#model.add(keras.layers.Conv2D(16, kernel_size=(4,4), padding='same', activation='relu'))\n",
    "#model.add(keras.layers.Conv2D(16, kernel_size=(2,2), padding='same', activation='relu'))\n",
    "#model.add(keras.layers.Conv2D(16, kernel_size=(1,1), padding='same', activation='relu'))\n",
    "\n",
    "# layer (X): max pooling 2D, has always been commented out, but you can uncomment it and see what it does\n",
    "#model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same', data_format=\"channels_last\"))\n",
    "\n",
    "# layer (2)\n",
    "model.add(keras.layers.Flatten(input_shape=(6,6,1),data_format = \"channels_last\"))\n",
    "\n",
    "# layer (3)\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "\n",
    "# layer 4, dropout 10%\n",
    "model.add(Dropout(0.1))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "                                                    \n",
    "# Layer (5), train the network\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\"]) \n",
    "# validation fraction is fraction of training sample used for testing (here 10%), epochs: number of times you run the CNN.\n",
    "epochs_number = 100 # change the number of epochs used in the training HERE\n",
    "model.fit(images_train, keras.utils.to_categorical(df_train[\"nUniqueSimTracksInSharedHit\"]>1), callbacks=[csv_logger], epochs=epochs_number, validation_split=0.1) \n",
    "\n",
    "# Prints out a summary of the training at the end\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss vs Epoch Plot script\n",
    "\n",
    "loss = []\n",
    "with open(\"training.txt\" )  as file:\n",
    "     for line in file:\n",
    "           # skipping the first line of the file since it contains column name (\"epoch\", \"loss\"..etc)\n",
    "            n = line.find(\"epoch\")\n",
    "            if n != -1:\n",
    "                continue\n",
    "            n = line.find(\",\",6, len(line)-1)\n",
    "            if n != -1:\n",
    "                x = line[n+1:n+ 7]\n",
    "                x = float(x)\n",
    "                loss.append(x)\n",
    "                continue\n",
    "#print(loss)\n",
    "\n",
    "epoch = []\n",
    "for i in range(0,epochs_number): # 100 epoch number\n",
    "    epoch.append(float(i+1))   \n",
    "#print(epoch)\n",
    "   \n",
    "p = np.poly1d(np.polyfit(epoch, loss, 10)) # using 10 degrees of freedom for our fit\n",
    "t = np.linspace(1,epochs_number, epochs_number*20) \n",
    "plt.plot(epoch, loss, 'o', t, p(t),  '-')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epoch Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate performance on independent sample, using CNN on Test sample\n",
    "ret = model.predict(images_test)\n",
    "np.save(\"result.pynb\",ret[:,1]) \n",
    "#print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating ROC curve inputs\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(keras.utils.to_categorical(df_test[\"nUniqueSimTracksInSharedHit\"]>1)[:,1], ret[:,1])\n",
    "#print fpr_keras,tpr_keras\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "#print auc_keras\n",
    "#print np.isnan(fpr_keras).all()\n",
    "#print len(fpr_keras),len(tpr_keras)\n",
    "np.save(\"fpr_keras.npy\",fpr_keras)\n",
    "np.save(\"tpr_keras.npy\",tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting ROC curve\n",
    "fpr_keras = np.load(\"fpr_keras.npy\")\n",
    "tpr_keras = np.load(\"tpr_keras.npy\")\n",
    "auc = np.trapz(tpr_keras,fpr_keras)\n",
    "#print auc\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC Curve (area = {:.3f})'.format(auc))\n",
    "plt.savefig(\"ROC.png\")\n",
    "plt.savefig(\"ROC.pdf\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: no overlap events between train and test \n",
    "pd.merge(df_train, df_test, on=[x for x in df_train.columns], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing our training data by number of hits\n",
    "print \"shared hits with at least 2 sim tracks:\"\n",
    "print float(sum(df_train[\"nUniqueSimTracksInSharedHit\"]>1))/len(df_train[\"nUniqueSimTracksInSharedHit\"])\n",
    "plt.hist(df_train[\"nUniqueSimTracksInSharedHit\"],histtype=\"step\",bins=6,range=(-0.5,5.5))\n",
    "plt.xlabel('Hits')\n",
    "plt.ylabel('Events')\n",
    "plt.title(\"Distribution of Hits in Training Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing our training data by merged (2 hits or more) vs not merged (1 hit) \n",
    "print \"shared hits with at least 2 sim tracks:\"\n",
    "print float(sum(df_train[\"nUniqueSimTracksInSharedHit\"]>1))/len(df_train[\"nUniqueSimTracksInSharedHit\"])\n",
    "plt.hist(df_train[\"nUniqueSimTracksInSharedHit\"]>1,histtype=\"step\",bins=2,range=(-0.5,1.5))\n",
    "plt.title(\"Distribution of Hits in Training Data\")\n",
    "plt.xticks([0,1],(\"Not Merged\",\"Merged\"))\n",
    "plt.ylabel('Events')\n",
    "plt.savefig(\"merged_dist.png\")\n",
    "plt.savefig(\"merged_dist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating signal and background for train and test data the preparing histograms for discriminant plot\n",
    "# Testing data\n",
    "signal = ret[df_test[\"nUniqueSimTracksInSharedHit\"]>1]\n",
    "background = ret[df_test[\"nUniqueSimTracksInSharedHit\"]<2]\n",
    "signal_plt = signal[:,1]\n",
    "background_plt = background[:,1]\n",
    "\n",
    "#Training data\n",
    "ret_train = model.predict(images_train)\n",
    "signal_train = ret_train[df_train[\"nUniqueSimTracksInSharedHit\"]>1]\n",
    "background_train = ret_train[df_train[\"nUniqueSimTracksInSharedHit\"]<2]\n",
    "signal_train_plt = signal_train[:,1]\n",
    "background_train_plt = background_train[:,1]\n",
    "Y_back_hist = np.histogram(background_train_plt, bins = 30, range = (0,1))[0]\n",
    "X_back_hist = np.histogram(background_train_plt, bins = 30, range = (0,1))[1]\n",
    "Y_sig_hist = np.histogram(signal_train_plt, bins = 30, range = (0,1))[0]\n",
    "X_sig_hist = np.histogram(signal_train_plt, bins = 30, range = (0,1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting Signal and Background Discriminants \n",
    "plt.hist(signal_plt, alpha = 0.5, color = 'b', label = 'Signal (test)', range = (0,1), bins = 30)\n",
    "plt.hist(background_plt, color = 'r', alpha = 0.5, label = 'Background (test)', range = (0,1), bins = 30)\n",
    "plt.scatter(X_back_hist[0:30] + 0.0166 , Y_back_hist, label='Background (train)', color ='r')\n",
    "plt.scatter(X_sig_hist[0:30] + 0.0166, Y_sig_hist, label='Signal (train)', color='b')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Discriminant')\n",
    "plt.ylabel('Events')\n",
    "plt.title('CNN Signal and Background Discriminants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Discriminant branch to Testing data only, could easily do it for Training data but we don't need to (for our purpose below)\n",
    "n_events_df_test = len(df_test.index) # number of events in df_test\n",
    "disc = []\n",
    "discriminants_test = model.predict(images_test) # returns (prob(notmergedhit), prob(merged hit)), the second number is our discriminant\n",
    "for i in range (0,n_events_df_test):\n",
    "    disc.append(discriminants_test[i][1]) \n",
    "df_test.insert(0, \"Discriminants\", disc) #inserting new column in our dataframe at position 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: let's see if Discriminants is non zero and it's at the 0th position\n",
    "#print df_test.head()\n",
    "#print df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel Picture Script\n",
    "def cluster_map(data_f):\n",
    "    # sorting by discriminant ascending\n",
    "    data_f = data_f.sort_values(\"Discriminants\", ascending = True)[0:len(data_f.index)-1]\n",
    "\n",
    "    shareds =  data_f\n",
    "    pixelColumns = [\"pixel_%i\" % x for x in range(36)]\n",
    "    pixels = shareds[pixelColumns].values\n",
    "\n",
    "    for row,hit,  in enumerate(pixels):\n",
    "        x_pos = []\n",
    "        y_pos = []\n",
    "        charge = []\n",
    "        for index,pixel in enumerate(hit):\n",
    "            if pixel!=0:\n",
    "                x_pos.append(index%6)\n",
    "                y_pos.append(np.floor(index/6))  \n",
    "                charge.append(pixel)\n",
    "        dis = np.around(data_f.iloc[row,0], decimals = 5)\n",
    "        text = \"     Event \" + str(row +1) + \" with discriminant \" + str(dis)\n",
    "        print text\n",
    "        \n",
    "        # Plotting Colorbar    \n",
    "        fig=plt.figure()\n",
    "        ax=plt.axes()\n",
    "        cax = plt.hist2d(x_pos,y_pos,weights=charge,bins=(6,6),range=((0,6),(0,6)))\n",
    "        cb=fig.colorbar(cax[3])\n",
    "        cb.set_ticks([0,max(charge)])\n",
    "        cb.set_label(\"normalized adc\",rotation=-90)\n",
    "\n",
    "        # Title, uses truth value\n",
    "        hits_column = data_f.columns.get_loc(\"nUniqueSimTracksInSharedHit\")\n",
    "        if data_f.iloc[row,hits_column] == 1 : # 1 hit\n",
    "            plt.title('         Not Merged Cluster Charge Map (discriminant = {:.3f})'.format(dis))\n",
    "        elif data_f.iloc[row,hits_column] > 1 : # 2 or more hits\n",
    "            plt.title('         Merged Cluster Charge Map (discriminant = {:.3f})'.format(dis))\n",
    "        else : # 0 hits\n",
    "            plt.title('         Null Cluster Charge Map (discriminant = {:.3f})'.format(dis))\n",
    "    \n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel Picture Script for [0, 0.1] discriminant testing events\n",
    "data = df_test [(df_test[\"Discriminants\"] < 0.1 )] \n",
    "cluster_map(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 0 - 0.1 discriminant events\n",
    "data[\"Discriminants\"].plot(kind='hist', title = \"Discriminant in the Range [0, 0.1]\", bins = 100, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel Picture Script for [0.3, 0.5] discriminant testing events\n",
    "data = df_test [(df_test[\"Discriminants\"] > 0.4 ) & (df_test[\"Discriminants\"] < 0.6 ) ] \n",
    "cluster_map(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 0.4 - 0.6 discriminant events\n",
    "data[\"Discriminants\"].plot(kind='hist', title = \"Discriminant in the Range [0.3, 0.5]\", bins = 100, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel Picture Script for [0.9, 1] discriminant testing events\n",
    "data = df_test [df_test[\"Discriminants\"] > 0.9 ] \n",
    "cluster_map(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 0.9 - 1 discriminant events\n",
    "data[\"Discriminants\"].plot(kind='hist' , title = \"Discriminant in the Range [0.9, 1]\", bins = 100, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Width and height script\n",
    "\n",
    "# including all testing events\n",
    "data = df_test \n",
    "# sorting by discriminant ascending\n",
    "data = data.sort_values(\"Discriminants\", ascending = True)[0:len(data.index)-1]\n",
    "\n",
    "shareds =  data\n",
    "pixelColumns = [\"pixel_%i\" % x for x in range(36)]\n",
    "pixels = shareds[pixelColumns].values\n",
    "width = [] # dx\n",
    "height = [] # dy\n",
    "\n",
    "for row,hit,  in enumerate(pixels):\n",
    "    x_pos = []\n",
    "    y_pos = []\n",
    "    charge = []\n",
    "    arra = np.zeros((6,6))\n",
    "    for index,pixel in enumerate(hit):   \n",
    "        if pixel!=0:\n",
    "            x_pos.append(index%6)\n",
    "            y_pos.append(np.floor(index/6))  \n",
    "            charge.append(pixel)\n",
    "            arra [5 - int(np.floor(index/6))][int(index%6)]= pixel\n",
    "    \n",
    "    #Evaluating width and height of every event\n",
    "    charge_in_x = np.sum(arra,axis=0)\n",
    "    charge_in_y = np.sum(arra,axis=1)\n",
    "    charge_x_values = np.where(charge_in_x>0)[0]\n",
    "    charge_y_values = np.where(charge_in_y>0)[0]\n",
    "    wid = charge_x_values[-1] - charge_x_values[0] + 1\n",
    "    hei = charge_y_values[-1] - charge_y_values[0] + 1\n",
    "    width.append(wid)\n",
    "    height.append(hei)\n",
    "\n",
    " \n",
    " # Uncomment this section to display each event information and pixel pictures\n",
    "     # Event info\n",
    "#    text = \"Event \" + str(row +1) + \" with discriminant \" + str(np.around(data.iloc[row,0], decimals = 5)) + \", width \"+ str(wid)+ \" and height \" +str(hei)\n",
    "#    print text\n",
    "#    # Plotting Colorbar  \n",
    "#    fig=plt.figure()\n",
    "#    ax=plt.axes()\n",
    "#    cax = plt.hist2d(x_pos,y_pos,weights=charge,bins=(6,6),range=((0,6),(0,6)))\n",
    "#    cb=fig.colorbar(cax[3])\n",
    "#    cb.set_ticks([0,max(charge)])\n",
    "#    cb.set_label(\"normalized adc\",rotation=-90)\n",
    "#\n",
    "#    # Title, uses truth value\n",
    "#    hits_column = df_test.columns.get_loc(\"nUniqueSimTracksInSharedHit\")\n",
    "#    if data.iloc[row,hits_column] == 1 : # 1 hit\n",
    "#        plt.title(\"Not Merged Cluster Charge Map\")\n",
    "#    elif data.iloc[row,hits_column] > 1 : # 2 or more hits\n",
    "#        plt.title(\"Merged Cluster Charge Map\")\n",
    "#    else : # 0 hits\n",
    "#        plt.title(\"Null Cluster Charge Map\")\n",
    "#    \n",
    "#    plt.xlabel(\"x\")\n",
    "#    plt.ylabel(\"y\")\n",
    "#    plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding width and height branch and checking they are there\n",
    "data.insert(1, \"Height\", height)\n",
    "data.insert(1, \"Width\", width)\n",
    "#print data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating signal and background for testing data\n",
    "signal = data[(data[\"nUniqueSimTracksInSharedHit\"]>1)]\n",
    "background = data[(data[\"nUniqueSimTracksInSharedHit\"]<2)]\n",
    "\n",
    "# Plotting CNN Signal and Background Width\n",
    "signal_plt_width = signal[\"Width\"]\n",
    "background_plt_width = background[\"Width\"]\n",
    "plt.hist(signal_plt_width, alpha = 0.5, color = 'b', label = 'Signal (test)', range = (1,6), bins = 6)\n",
    "plt.hist(background_plt_width, color = 'r', alpha = 0.5, label = 'Background (test)', range = (1,6), bins = 6)\n",
    "plt.legend(loc='best')\n",
    "plt.title('CNN Signal and Background Width')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting CNN Signal and Background Height\n",
    "signal_plt_height = signal[\"Height\"]\n",
    "background_plt_height = background[\"Height\"]\n",
    "plt.hist(signal_plt_height, alpha = 0.5, color = 'b', label = 'Signal (test)', range = (1,6), bins = 6)\n",
    "plt.hist(background_plt_height, color = 'r', alpha = 0.5, label = 'Background (test)', range = (1,6), bins = 6)\n",
    "plt.legend(loc='best')\n",
    "plt.title('CNN Signal and Background Height')\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Events')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
