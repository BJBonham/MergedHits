{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pylab\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats.stats import pearsonr\n",
    "%matplotlib inline\n",
    "\n",
    "# Define to_image function\n",
    "pixels = [\"pixel_{0}\".format(i) for i in range(400)] # 20*20 = 400\n",
    "def to_image(df):\n",
    "    return  np.expand_dims(np.expand_dims(df[pixels], axis=-1).reshape(-1,20,20), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File /uscms_data/d3/bbonham/TrackerProject/TrackingDstar/LambaAnalyzer/output_of_postprocess/AllHits/AbsoluteCharge/output_final.h5 does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-da803dc3d908>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Import data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m df = pd.read_hdf(\"/uscms_data/d3/bbonham/TrackerProject/TrackingDstar/LambaAnalyzer/output_of_postprocess/\"+datafilename, \n\u001b[0;32m---> 14\u001b[0;31m                  key=\"df\", mode='r')\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Print dataframe info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py2-pandas/0.23.4-ikaegh/lib/python2.7/site-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             raise compat.FileNotFoundError(\n\u001b[0;32m--> 371\u001b[0;31m                 'File %s does not exist' % path_or_buf)\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File /uscms_data/d3/bbonham/TrackerProject/TrackingDstar/LambaAnalyzer/output_of_postprocess/AllHits/AbsoluteCharge/output_final.h5 does not exist"
     ]
    }
   ],
   "source": [
    "## Import the data ##\n",
    "\n",
    "# List file names\n",
    "datafilenames = [\"SharedHits/NormalizedCharge/output_final.h5\",\"SharedHits/AbsoluteCharge/output_final.h5\",\n",
    "                \"Shared100NonShared/NormalizedCharge/output_final.h5\",\"Shared100NonShared/AbsoluteCharge/output_final.h5\",\n",
    "                \"AllHits/NormalizedCharge/output_final.h5\",\"AllHits/AbsoluteCharge/output_final.h5\"]\n",
    "\n",
    "# Select file you want to use\n",
    "filenumber = 5\n",
    "datafilename = datafilenames[filenumber]\n",
    "\n",
    "# Import data\n",
    "df = pd.read_hdf(\"/uscms_data/d3/bbonham/TrackerProject/TrackingDstar/LambaAnalyzer/output_of_postprocess/\"+datafilename, \n",
    "                 key=\"df\", mode='r')\n",
    "\n",
    "# Print dataframe info\n",
    "print '\\033[1m' + datafilename[:-16] + '\\033[0m' # name printed in bold\n",
    "print df.info()\n",
    "\n",
    "# Shared Hits Signal Region\n",
    "if filenumber == 0 or filenumber == 1:\n",
    "    signalstring = \"['nUniqueSimTracksInSharedHit']>=2\"\n",
    "    backgroundstring = \"['nUniqueSimTracksInSharedHit']<=1\"\n",
    "# All Hits Signal Region\n",
    "if filenumber in [2,3,4,5]:\n",
    "    signalstring = \"['isSharedHit']==1\"\n",
    "    backgroundstring = \"['isSharedHit']!=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model('/uscms/home/bbonham/nobackup/TrackerProject/MergedHits/Brandon/Trained_Models_isShared=1/TrainedModel_'+datafilename[:-16].replace('/','_')+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduce the train-test split from when you trained the model.\n",
    "\n",
    "# Seed must be the same integer as when you trained the model. Always 10 for me. \n",
    "# Alternatively, you could save df_train and load it, but I chose to do it with a consistent seed instead. \n",
    "train_test_seed = 10\n",
    "df_train,df_test = train_test_split(df,test_size=0.5,random_state=train_test_seed)\n",
    "images_train = to_image(df_train)\n",
    "images_test = to_image(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal_string below should be double checked, or the roc curve may be wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "\n",
    "ret = model.predict(images_test)\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(keras.utils.to_categorical(eval(\"df_test\"+signalstring))[:,1], ret[:,1])\n",
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "auc = np.trapz(tpr_keras,fpr_keras)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC Curve (area = {:.3f})'.format(auc))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizing our training data by number of hits\n",
    "print \"shared hits with at least 2 sim tracks:\"\n",
    "print float(sum(df_train[\"nUniqueSimTracksInSharedHit\"]>1))/len(df_train[\"nUniqueSimTracksInSharedHit\"])\n",
    "plt.hist(df_train[\"nUniqueSimTracksInSharedHit\"],histtype=\"step\",bins=6,range=(-0.5,5.5))\n",
    "plt.xlabel('# Unique Simulation Tracks')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')\n",
    "plt.title(\"Distribution of Simulation Tracks in Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing our training data by merged (2 hits or more) vs not merged (1 hit) \n",
    "print \"shared hits with at least 2 sim tracks:\"\n",
    "print float(sum(df_train[\"nUniqueSimTracksInSharedHit\"]>1))/len(df_train[\"nUniqueSimTracksInSharedHit\"])\n",
    "plt.hist(df_train[\"nUniqueSimTracksInSharedHit\"]>1,histtype=\"step\",bins=2,range=(-0.5,1.5), color = 'r')\n",
    "plt.title(\"Distribution of Merged Hits vs Not Merged Hits in Training Data\")\n",
    "plt.xticks([0,1],(\"Not Merged\",\"Merged\"))\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following two cells depend on the definition of signal and background, which I'm not thrilled to change right now. \n",
    "# I would rather alter them automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separating signal and background for train and test data then preparing histograms for discriminant plot\n",
    "# Testing data\n",
    "\n",
    "signal = ret[ eval(\"df_test\"+signalstring) ]\n",
    "background = ret[ eval(\"df_test\"+backgroundstring) ]\n",
    "signal_plt = signal[:,1]\n",
    "background_plt = background[:,1]\n",
    "\n",
    "#Training data\n",
    "ret_train = model.predict(images_train)\n",
    "signal_train = ret_train[ eval(\"df_train\"+signalstring) ]\n",
    "background_train = ret_train[ eval(\"df_train\"+backgroundstring) ] # Non-Merged Hits\n",
    "signal_train_plt = signal_train[:,1]\n",
    "background_train_plt = background_train[:,1]\n",
    "Y_back_hist = np.histogram(background_train_plt, bins = 30, range = (0,1))[0]\n",
    "X_back_hist = np.histogram(background_train_plt, bins = 30, range = (0,1))[1]\n",
    "Y_sig_hist = np.histogram(signal_train_plt, bins = 30, range = (0,1))[0]\n",
    "X_sig_hist = np.histogram(signal_train_plt, bins = 30, range = (0,1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting Signal and Background Discriminants\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.hist(signal_plt, alpha = 0.5, color = 'b', label = 'Signal (test)', range = (0,1), bins = 30,log=True)\n",
    "plt.hist(background_plt, color = 'r', alpha = 0.5, label = 'Background (test)', range = (0,1), bins = 30,log=True)\n",
    "plt.scatter(X_back_hist[0:30] + 0.0166 , Y_back_hist, label='Background (train)', color ='r')\n",
    "plt.scatter(X_sig_hist[0:30] + 0.0166, Y_sig_hist, label='Signal (train)', color='b')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Discriminant')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')\n",
    "plt.title('CNN Signal and Background Discriminants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Discriminant branch to Testing data only, could easily do it for Training data but we don't need to (for our purpose below)\n",
    "n_events_df_test = len(df_test.index) # number of events in df_test\n",
    "disc = []\n",
    "discriminants_test = model.predict(images_test) # returns (prob(notmergedhit), prob(merged hit)), the second number is our discriminant\n",
    "for i in range (0,n_events_df_test):\n",
    "    disc.append(discriminants_test[i][1]) \n",
    "df_test.insert(0, \"Discriminants\", disc) #inserting new column in our dataframe at position 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel Picture Script\n",
    "def cluster_map(data_f):\n",
    "    # sorting by discriminant ascending\n",
    "    data_f = data_f.sort_values(\"Discriminants\", ascending = True)[0:len(data_f.index)-1]\n",
    "\n",
    "    shareds =  data_f\n",
    "    pixelColumns = [\"pixel_%i\" % x for x in range(400)] # 400\n",
    "    pixels = shareds[pixelColumns].values\n",
    "\n",
    "    for row,hit,  in enumerate(pixels):\n",
    "        x_pos = []\n",
    "        y_pos = []\n",
    "        charge = []\n",
    "        for index,pixel in enumerate(hit):\n",
    "            if pixel!=0:\n",
    "                x_pos.append(index%20)\n",
    "                y_pos.append(np.floor(index/20))  \n",
    "                charge.append(pixel)\n",
    "        dis = np.around(data_f.iloc[row,0], decimals = 5)\n",
    "        text = \"Reconstructed $\\Lambda$ \" + str(row +1) + \" with discriminant \" + str(dis)\n",
    "        print text\n",
    "        \n",
    "        # Plotting Colorbar    \n",
    "        fig=plt.figure()\n",
    "        ax=plt.axes()\n",
    "        cax = plt.hist2d(x_pos,y_pos,weights=charge,bins=(20,20),range=((0,20),(0,20)))\n",
    "        cb=fig.colorbar(cax[3])\n",
    "        cb.set_ticks([0,max(charge)])\n",
    "        cb.set_label(\"Scaled ADC\",rotation=-90)\n",
    "\n",
    "        # Title, uses truth value\n",
    "        hits_column = data_f.columns.get_loc(\"nUniqueSimTracksInSharedHit\")\n",
    "        if data_f.iloc[row,hits_column] == 1 : # 1 hit\n",
    "            plt.title('         Not Merged Cluster Charge Map (discriminant = {:.3f})'.format(dis))\n",
    "        elif data_f.iloc[row,hits_column] > 1 : # 2 or more hits\n",
    "            plt.title('         Merged Cluster Charge Map (discriminant = {:.3f})'.format(dis))\n",
    "        else : # 0 hits\n",
    "            plt.title('         Null Cluster Charge Map (discriminant = {:.3f})'.format(dis))\n",
    "    \n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Discriminant Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 0 - 0.1 discriminant events\n",
    "df_test[\"Discriminants\"].plot(kind='hist', title = \"Discriminant Distribution\", bins = 100, figsize=(12,6),log=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminants between [0.0,0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pixel Picture Script for [0, 0.1] discriminant testing events\n",
    "\n",
    "n_pictures = 1 \n",
    "cluster_map(df_test[(df_test[\"Discriminants\"] < 0.1 )][:(1+n_pictures)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Distribution of 0 - 0.1 discriminant events\n",
    "df_test[(df_test[\"Discriminants\"] < 0.1 )][\"Discriminants\"].plot(kind='hist', title = \"Discriminant in the Range [0, 0.1]\", bins = 100, figsize=(12,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminants between [0.4,0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pixel Picture Script for [0.4, 0.6] discriminant testing events\n",
    "\n",
    "n_pictures = 1 \n",
    "cluster_map(df_test[(df_test[\"Discriminants\"] > 0.3 ) & (df_test[\"Discriminants\"] < 0.6 )][:(1+n_pictures)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 0.4 - 0.6 discriminant events\n",
    "df_test[(df_test[\"Discriminants\"] > 0.4 ) & (df_test[\"Discriminants\"] < 0.6 )][\"Discriminants\"].plot(kind='hist', title = \"Discriminant in the Range [0.4, 0.6]\", bins = 100, figsize=(12,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminants Between [0.9,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pixel Picture Script for [0.9, 1] discriminant testing events\n",
    "n_pictures = 1 \n",
    "cluster_map(df_test[df_test[\"Discriminants\"] > 0.9][:(1+n_pictures)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 0.9 - 1 discriminant events\n",
    "df_test[df_test[\"Discriminants\"] > 0.9][\"Discriminants\"].plot(kind='hist' , title = \"Discriminant in the Range [0.9, 1]\", bins = 100, figsize=(12,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking at the flatten 2D maps either in x or y <br>\n",
    "pixelCharge is the pixel charge of the flattened 2D map, sum(pixelCharge) = 1  <br>\n",
    "pixelPos is the position of the flattened 2D maps pixel (range is 1 to 6)  <br>\n",
    "$\\overline{x} = \\sum_1^6 \\text{pixelCharge}^i \\ \\times \\ \\text{pixelPos}^i$  <br>\n",
    "$x^{RMS} = \\sqrt{  \\sum_1^6 (\\overline{x} - \\text{pixelPos}^i \\ \\times \\ \\text{pixelCharge}^i)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for dx, dy, x^RMS, y^RMS \n",
    "\n",
    "# including all testing events\n",
    "data = df_test \n",
    "# sorting by discriminant ascending\n",
    "#data = data.sort_values(\"Discriminants\", ascending = True)[0:len(data.index)-1]\n",
    "\n",
    "shareds =  data\n",
    "pixelColumns = [\"pixel_%i\" % x for x in range(400)]\n",
    "pixels = shareds[pixelColumns].values\n",
    "width = [] # dx\n",
    "length = [] # dy\n",
    "x_rms = [] \n",
    "y_rms = []\n",
    "\n",
    "for row,hit,  in enumerate(pixels):\n",
    "    x_pos = []\n",
    "    y_pos = []\n",
    "    charge = []\n",
    "    arra = np.zeros((20,20))\n",
    "    for index,pixel in enumerate(hit):   \n",
    "        if pixel!=0:\n",
    "            x_pos.append(index%20)\n",
    "            y_pos.append(np.floor(index/20))  \n",
    "            charge.append(pixel)\n",
    "            arra [19 - int(np.floor(index/20))][int(index%20)]= pixel\n",
    "    \n",
    "    #Evaluating width and height of every event\n",
    "    charge_in_x = np.sum(arra,axis=0)\n",
    "    charge_in_y = np.sum(arra,axis=1)\n",
    "    charge_x_values = np.where(charge_in_x>0)[0]\n",
    "    charge_y_values = np.where(charge_in_y>0)[0]\n",
    "    wid = charge_x_values[-1] - charge_x_values[0] + 1\n",
    "    le = charge_y_values[-1] - charge_y_values[0] + 1\n",
    "    width.append(wid)\n",
    "    length.append(le)\n",
    "    \n",
    "    # Evaluating x^RMS, y^RMS of every cluster\n",
    "    mean_x = 0\n",
    "    mean_y = 0\n",
    "    x_ms = 0\n",
    "    y_ms = 0\n",
    "    for i in range (0,20):\n",
    "        mean_x = charge_in_x[i]*(i+1) + mean_x\n",
    "        mean_y = charge_in_y[i]*(i+1) + mean_y\n",
    "    for i in range (0,20):\n",
    "        if charge_in_x[i] > 0:\n",
    "            x_ms = (mean_x - charge_in_x[i]*(i+1))**2 + x_ms\n",
    "        if charge_in_y[i] > 0:\n",
    "            y_ms = (mean_y - charge_in_y[i]*(i+1))**2 + y_ms\n",
    "    x_rms.append(np.sqrt(x_ms))\n",
    "    y_rms.append(np.sqrt(y_ms))\n",
    "\n",
    " \n",
    " # Uncomment this section to display each event information and pixel pictures\n",
    "     # Event info\n",
    "#    text = \"Event \" + str(row +1) + \" with discriminant \" + str(np.around(data.iloc[row,0], decimals = 5)) + \", width \"+ str(wid)+ \" and length \" +str(le)\n",
    "#    print text\n",
    "#    # Plotting Colorbar  \n",
    "#    fig=plt.figure()\n",
    "#    ax=plt.axes()\n",
    "#    cax = plt.hist2d(x_pos,y_pos,weights=charge,bins=(6,6),range=((0,6),(0,6)))\n",
    "#    cb=fig.colorbar(cax[3])\n",
    "#    cb.set_ticks([0,max(charge)])\n",
    "#    cb.set_label(\"normalized adc\",rotation=-90)\n",
    "#\n",
    "#    # Title, uses truth value\n",
    "#    hits_column = df_test.columns.get_loc(\"nUniqueSimTracksInSharedHit\")\n",
    "#    if data.iloc[row,hits_column] == 1 : # 1 hit\n",
    "#        plt.title(\"Not Merged Cluster Charge Map\")\n",
    "#    elif data.iloc[row,hits_column] > 1 : # 2 or more hits\n",
    "#        plt.title(\"Merged Cluster Charge Map\")\n",
    "#    else : # 0 hits\n",
    "#        plt.title(\"Null Cluster Charge Map\")\n",
    "#    \n",
    "#    plt.xlabel(\"x\")\n",
    "#    plt.ylabel(\"y\")\n",
    "#    plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding width and height branch and checking they are there\n",
    "data.insert(1, \"Length\", length)\n",
    "data.insert(1, \"Width\", width)\n",
    "\n",
    "# Adding width RMS and height RMS branch and checking they are there\n",
    "data.insert(1, \"Length RMS\", y_rms)\n",
    "data.insert(1, \"Width RMS\", x_rms)\n",
    "\n",
    "#print data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating signal and background for testing data\n",
    "signal = data[ eval(\"data\"+signalstring) ]\n",
    "background = data[ eval(\"data\"+backgroundstring) ]\n",
    "\n",
    "# Plotting CNN Signal and Background Width\n",
    "signal_plt_width = signal[\"Width\"]\n",
    "background_plt_width = background[\"Width\"]\n",
    "plt.hist(signal_plt_width,  alpha = 0.5, color = 'b', label = 'Merged Hit', range = (1,10), bins = 9, density=True)\n",
    "plt.hist(background_plt_width, alpha = 0.5, color = 'r', label = 'Not Merged Hit', range = (1,10), bins = 9, density=True)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Merged vs Not Merged $\\Delta x$ in Testing Data')\n",
    "plt.xlabel('$\\Delta x$')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting CNN Signal and Background Height\n",
    "signal_plt_height = signal[\"Length\"]\n",
    "background_plt_height = background[\"Length\"]\n",
    "plt.hist(signal_plt_height, alpha = 0.5, color = 'b', label = 'Merged Hit', range = (1,20), bins = 19, density=True)\n",
    "plt.hist(background_plt_height, color = 'r', alpha = 0.5, label = 'Not Merged Hit', range = (1,20), bins = 19,density=True)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Merged vs Not Merged $\\Delta y$ in Testing Data')\n",
    "plt.xlabel('$\\Delta y$')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of Length vs Width in Testing for correlation in Merged Hits   \n",
    "x = signal_plt_width\n",
    "y = signal_plt_height  \n",
    "correlation = pearsonr(x,y)[0] \n",
    "plt.xlabel('$\\Delta x$')\n",
    "plt.ylabel('$\\Delta y$')\n",
    "plt.title('$\\Delta y$ vs $\\Delta x$ for Merged Clusters in Testing') #(corr = {:.4f})'.format(correlation))\n",
    "plt.hist2d(x, y,bins = (20, 20), range =[[0, 20], [0,20]], cmap=plt.cm.jet) # cmap=plt.cm.Greys\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of Length vs Width in Testing for correlation in Not Merged Hits\n",
    "x = background_plt_width\n",
    "y = background_plt_height\n",
    "correlation = pearsonr(x,y)[0] \n",
    "plt.xlabel('$\\Delta x$')\n",
    "plt.ylabel('$\\Delta y$')\n",
    "plt.title('$\\Delta y$ vs $\\Delta x$ for Not Merged Clusters in Testing') # (corr = {:.4f})'.format(correlation))\n",
    "plt.hist2d(x, y,  bins = (20, 20), range =[[0, 20], [0,20]],  cmap=plt.cm.jet)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting CNN Signal and Background Width\n",
    "signal = data[(data[\"nUniqueSimTracksInSharedHit\"]>1)]\n",
    "background = data[(data[\"nUniqueSimTracksInSharedHit\"]<2)]\n",
    "signal_plt_width = signal[\"Width RMS\"]\n",
    "background_plt_width = background[\"Width RMS\"]\n",
    "plt.hist(signal_plt_width, alpha = 0.5, color = 'b', label = 'Merged Hit', range = (0,100), bins = 80, density=True)\n",
    "plt.hist(background_plt_width, color = 'r', alpha = 0.5, label = 'Not Merged Hit', range = (0,100), bins = 80, density=True)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Merged vs Not Merged $x^{RMS}$ in Testing Data (Normalized)')\n",
    "plt.xlabel('$x^{RMS}$')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting CNN Signal and Background Height\n",
    "signal_plt_height = signal[\"Length RMS\"]\n",
    "background_plt_height = background[\"Length RMS\"]\n",
    "plt.hist(signal_plt_height, alpha = 0.5, color = 'b', label = 'Merged Hit', range = (0,400), bins = 100, density=True)\n",
    "plt.hist(background_plt_height, color = 'r', alpha = 0.5, label = 'Not Merged Hit', range = (0,400), bins = 100, density=True)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Merged vs Not Merged $y^{RMS}$ in Testing Data (Normalized)')\n",
    "plt.xlabel('$y^{RMS}$')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of Length vs Width in Testing for correlation in Merged Hits   \n",
    "x = signal_plt_width\n",
    "y = signal_plt_height  \n",
    "correlation = pearsonr(x,y)[0]\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel('$x^{RMS}$')\n",
    "plt.ylabel('$y^{RMS}$')\n",
    "plt.title('$y^{RMS}$ vs $x^{RMS}$ for Merged Clusters in Testing') #(corr = {:.4f})'.format(correlation))\n",
    "plt.hist2d(x, y,bins = (60, 60), range =[[0, 100], [0,100]], cmap=plt.cm.jet) # cmap=plt.cm.Greys\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of Length vs Width in Testing for correlation in Not Merged Hits\n",
    "x = background_plt_width\n",
    "y = background_plt_height\n",
    "correlation = pearsonr(x,y)[0]\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel('$x^{RMS}$')\n",
    "plt.ylabel('$y^{RMS}$')\n",
    "plt.title('$y^{RMS}$ vs $x^{RMS}$ for Not Merged Clusters in Testing') # (corr = {:.4f})'.format(correlation))\n",
    "plt.hist2d(x, y,bins = (60, 60), range =[[0, 60], [0,60]], cmap=plt.cm.jet) # cmap=plt.cm.Greys\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
