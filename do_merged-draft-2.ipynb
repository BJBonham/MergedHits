{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to run this cell twice or else the following cells won't run.\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from IPython.display import FileLink, FileLinks\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 image has 6x6 pixels = 36 pixels \n",
    "pixels = [\"pixel_{0}\".format(i) for i in range(36)]\n",
    "def to_image(df):\n",
    "    return  np.expand_dims(np.expand_dims(df[pixels], axis=-1).reshape(-1,6,6), axis=-1)\n",
    "\n",
    "# You need to email hichemb@princeton.edu to request access to this directory, or else this line will not work\n",
    "df = pd.read_hdf(\"/eos/user/h/hboucham/SWAN_projects/MergedHits/output_final.h5\", key=\"df\", mode='r') # do not write to this file !\n",
    "\n",
    "# If you want to run \"file.h5\" locally use the following lines:\n",
    "# store_train = pd.HDFStore(\"file.h5\")\n",
    "# df = store_train.select(\"df\" , stop = -1) # df here is like a tree1 in Root\n",
    "\n",
    "#print df.info()\n",
    "\n",
    "#Last Cuts and selections:\n",
    "#cut on DeltaR and nUniqueSimTracksInSharedHit\n",
    "df = df[(df[\"GenDeltaR\"]<0.1) & (df[\"nUniqueSimTracksInSharedHit\"]>-1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set before removing single pixel events\n",
    "df_old = df\n",
    "df_old_train=df.sample(frac=0.5)\n",
    "df_old_test=df.drop(df_old_train.index)\n",
    "images_old_train = to_image(df_old_train)\n",
    "images_old_test = to_image(df_old_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing events that have single pixel since the neural network cannot tell whether it's merged or not, there is simply not enough information.\n",
    "pixelColumns = [\"pixel_%i\" % x for x in range(36)]\n",
    "pixels_df = df[pixelColumns].values\n",
    "# This printout is a sanity check, there 36 pixels so we expect pixels_df to have 36 columns\n",
    "#print(pixels_df[0].shape)\n",
    "pixel_number = pixels_df.astype(bool).sum(axis=1)\n",
    "df.insert(0, \"Pixel_number\", pixel_number)\n",
    "# the df.info() printouts allows us to see how many events were removed.\n",
    "#print df.info()\n",
    "df = df[df[\"Pixel_number\"]>1]\n",
    "#print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frac=0.5 sets half training and half testing\n",
    "df_train=df.sample(frac=0.5)\n",
    "df_test=df.drop(df_train.index)\n",
    "images_train = to_image(df_train)\n",
    "images_test = to_image(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: printout (events, variables) Variables include 36 pixels, and a few others you can find using df.info() command\n",
    "print \"Test Data Shape: \",df_test.shape\n",
    "print \"Train Data Shape: \",df_train.shape\n",
    "#print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the CNN\n",
    "# Adding layers to Neural Network: (1) is convolutional,(1.5) 2D layer ,(2) flatten output then feed it to (3) which is a regular neural network.\n",
    "# (4) drops nodes in NN to avoid overfitting, finallly (5) outputs 2 values (prob(notmergedhit), prob(merged hit)), must add up to 1.\n",
    "\n",
    "# Define the network\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#layer (1)\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(4,4), padding='same', activation='relu'))\n",
    "\n",
    "#layer (1.5) : you can play with these layers individually or together until you find the best combination\n",
    "#model.add(keras.layers.Conv2D(16, kernel_size=(2,2), padding='same', activation='relu'))\n",
    "#model.add(keras.layers.Conv2D(16, kernel_size=(4,4), padding='same', activation='relu'))\n",
    "#model.add(keras.layers.Conv2D(16, kernel_size=(1,1), padding='same', activation='relu'))\n",
    "\n",
    "# layer (X): max pooling 2D, has always been commented out, but you can uncomment it and see what it does\n",
    "#model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same', data_format=\"channels_last\"))\n",
    "\n",
    "# layer (2)\n",
    "model.add(keras.layers.Flatten(input_shape=(6,6,1),data_format = \"channels_last\"))\n",
    "\n",
    "# layer (3)\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "\n",
    "# layer 4, dropout 10%\n",
    "model.add(Dropout(0.1))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "                                                    \n",
    "# Layer (5), train the network\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\"]) \n",
    "\n",
    "# epochs: number of times you run the CNN.\n",
    "epochs_number = 100 # change the number of epochs used in the training HERE\n",
    "\n",
    "# early stopping callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# model checkpoint callback\n",
    "# this saves our model architecture + parameters into dense_model.h5\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint('CNN_model.h5', monitor='val_loss', \n",
    "                                    save_best_only=True, \n",
    "                                   save_weights_only=False, mode='auto', \n",
    "                                   period=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "history = model.fit(images_train,\n",
    "                     keras.utils.to_categorical(df_train[\"nUniqueSimTracksInSharedHit\"]>1), \n",
    "                    epochs = epochs_number, \n",
    "                    callbacks=[early_stopping, model_checkpoint], \n",
    "                    validation_split=0.1)\n",
    "# validation split is fraction of training sample used for testing (here 10%) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss vs epoch and acc vs epoch plots\n",
    "%matplotlib inline\n",
    "\n",
    "# plot loss vs epoch\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "ax.plot(history.history['loss'], label='loss')\n",
    "ax.plot(history.history['val_loss'], label='val_loss')\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('loss')\n",
    "pylab.ylim([0,0.6])\n",
    "\n",
    "# plot accuracy vs epoch\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "ax.plot(history.history['acc'], label='acc')\n",
    "ax.plot(history.history['val_acc'], label='val_acc')\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('acc')\n",
    "pylab.ylim([0,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate performance on independent sample, using CNN on Test sample\n",
    "ret = model.predict(images_test)\n",
    "np.save(\"result.pynb\",ret[:,1]) \n",
    "#print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating ROC curve inputs\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(keras.utils.to_categorical(df_test[\"nUniqueSimTracksInSharedHit\"]>1)[:,1], ret[:,1])\n",
    "#print fpr_keras,tpr_keras\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "#print auc_keras\n",
    "#print np.isnan(fpr_keras).all()\n",
    "#print len(fpr_keras),len(tpr_keras)\n",
    "np.save(\"fpr_keras.npy\",fpr_keras)\n",
    "np.save(\"tpr_keras.npy\",tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting ROC curve\n",
    "fpr_keras = np.load(\"fpr_keras.npy\")\n",
    "tpr_keras = np.load(\"tpr_keras.npy\")\n",
    "auc = np.trapz(tpr_keras,fpr_keras)\n",
    "#print auc\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC Curve (area = {:.3f})'.format(auc))\n",
    "plt.savefig(\"ROC.png\")\n",
    "plt.savefig(\"ROC.pdf\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: no overlap events between train and test \n",
    "pd.merge(df_train, df_test, on=[x for x in df_train.columns], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing our training data by number of hits\n",
    "print \"shared hits with at least 2 sim tracks:\"\n",
    "print float(sum(df_train[\"nUniqueSimTracksInSharedHit\"]>1))/len(df_train[\"nUniqueSimTracksInSharedHit\"])\n",
    "plt.hist(df_train[\"nUniqueSimTracksInSharedHit\"],histtype=\"step\",bins=6,range=(-0.5,5.5))\n",
    "plt.xlabel('# Unique Simulation Tracks')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')\n",
    "plt.title(\"Distribution of Simulation Tracks in Training Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing our training data by merged (2 hits or more) vs not merged (1 hit) \n",
    "print \"shared hits with at least 2 sim tracks:\"\n",
    "print float(sum(df_train[\"nUniqueSimTracksInSharedHit\"]>1))/len(df_train[\"nUniqueSimTracksInSharedHit\"])\n",
    "plt.hist(df_old_train[\"nUniqueSimTracksInSharedHit\"]>1,histtype=\"step\",bins=2,range=(-0.5,1.5), label = 'w single pixel cluster')\n",
    "plt.hist(df_train[\"nUniqueSimTracksInSharedHit\"]>1,histtype=\"step\",bins=2,range=(-0.5,1.5), color = 'r', label = 'w/o single pixel cluster')\n",
    "plt.title(\"Distribution of Merged Hits vs Not Merged Hits in Training Data           \")\n",
    "plt.xticks([0,1],(\"Not Merged\",\"Merged\"))\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(\"merged_dist.png\")\n",
    "plt.savefig(\"merged_dist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating signal and background for train and test data the preparing histograms for discriminant plot\n",
    "# Testing data\n",
    "signal = ret[df_test[\"nUniqueSimTracksInSharedHit\"]>1]\n",
    "background = ret[df_test[\"nUniqueSimTracksInSharedHit\"]<2]\n",
    "signal_plt = signal[:,1]\n",
    "background_plt = background[:,1]\n",
    "\n",
    "#Training data\n",
    "ret_train = model.predict(images_train)\n",
    "signal_train = ret_train[df_train[\"nUniqueSimTracksInSharedHit\"]>1]\n",
    "background_train = ret_train[df_train[\"nUniqueSimTracksInSharedHit\"]<2]\n",
    "signal_train_plt = signal_train[:,1]\n",
    "background_train_plt = background_train[:,1]\n",
    "Y_back_hist = np.histogram(background_train_plt, bins = 30, range = (0,1))[0]\n",
    "X_back_hist = np.histogram(background_train_plt, bins = 30, range = (0,1))[1]\n",
    "Y_sig_hist = np.histogram(signal_train_plt, bins = 30, range = (0,1))[0]\n",
    "X_sig_hist = np.histogram(signal_train_plt, bins = 30, range = (0,1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting Signal and Background Discriminants \n",
    "plt.hist(signal_plt, alpha = 0.5, color = 'b', label = 'Signal (test)', range = (0,1), bins = 30)\n",
    "plt.hist(background_plt, color = 'r', alpha = 0.5, label = 'Background (test)', range = (0,1), bins = 30)\n",
    "plt.scatter(X_back_hist[0:30] + 0.0166 , Y_back_hist, label='Background (train)', color ='r')\n",
    "plt.scatter(X_sig_hist[0:30] + 0.0166, Y_sig_hist, label='Signal (train)', color='b')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Discriminant')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')\n",
    "plt.title('CNN Signal and Background Discriminants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Discriminant branch to Testing data only, could easily do it for Training data but we don't need to (for our purpose below)\n",
    "n_events_df_test = len(df_test.index) # number of events in df_test\n",
    "disc = []\n",
    "discriminants_test = model.predict(images_test) # returns (prob(notmergedhit), prob(merged hit)), the second number is our discriminant\n",
    "for i in range (0,n_events_df_test):\n",
    "    disc.append(discriminants_test[i][1]) \n",
    "df_test.insert(0, \"Discriminants\", disc) #inserting new column in our dataframe at position 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: let's see if Discriminants is non zero and it's at the 0th position\n",
    "#print df_test.head()\n",
    "#print df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel Picture Script\n",
    "def cluster_map(data_f):\n",
    "    # sorting by discriminant ascending\n",
    "    data_f = data_f.sort_values(\"Discriminants\", ascending = True)[0:len(data_f.index)-1]\n",
    "\n",
    "    shareds =  data_f\n",
    "    pixelColumns = [\"pixel_%i\" % x for x in range(36)]\n",
    "    pixels = shareds[pixelColumns].values\n",
    "\n",
    "    for row,hit,  in enumerate(pixels):\n",
    "        x_pos = []\n",
    "        y_pos = []\n",
    "        charge = []\n",
    "        for index,pixel in enumerate(hit):\n",
    "            if pixel!=0:\n",
    "                x_pos.append(index%6)\n",
    "                y_pos.append(np.floor(index/6))  \n",
    "                charge.append(pixel)\n",
    "        dis = np.around(data_f.iloc[row,0], decimals = 5)\n",
    "        text = \"Reconstructed $\\Lambda$ \" + str(row +1) + \" with discriminant \" + str(dis)\n",
    "        print text\n",
    "        \n",
    "        # Plotting Colorbar    \n",
    "        fig=plt.figure()\n",
    "        ax=plt.axes()\n",
    "        cax = plt.hist2d(x_pos,y_pos,weights=charge,bins=(6,6),range=((0,6),(0,6)))\n",
    "        cb=fig.colorbar(cax[3])\n",
    "        cb.set_ticks([0,max(charge)])\n",
    "        cb.set_label(\"normalized adc\",rotation=-90)\n",
    "\n",
    "        # Title, uses truth value\n",
    "        hits_column = data_f.columns.get_loc(\"nUniqueSimTracksInSharedHit\")\n",
    "        if data_f.iloc[row,hits_column] == 1 : # 1 hit\n",
    "            plt.title('         Not Merged Cluster Charge Map (discriminant = {:.3f})'.format(dis))\n",
    "        elif data_f.iloc[row,hits_column] > 1 : # 2 or more hits\n",
    "            plt.title('         Merged Cluster Charge Map (discriminant = {:.3f})'.format(dis))\n",
    "        else : # 0 hits\n",
    "            plt.title('         Null Cluster Charge Map (discriminant = {:.3f})'.format(dis))\n",
    "    \n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel Picture Script for [0, 0.1] discriminant testing events\n",
    "data = df_test [(df_test[\"Discriminants\"] < 0.1 )] \n",
    "cluster_map(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 0 - 0.1 discriminant events\n",
    "data[\"Discriminants\"].plot(kind='hist', title = \"Discriminant in the Range [0, 0.1]\", bins = 100, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel Picture Script for [0.3, 0.5] discriminant testing events\n",
    "data = df_test [(df_test[\"Discriminants\"] > 0.4 ) & (df_test[\"Discriminants\"] < 0.6 ) ] \n",
    "cluster_map(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 0.4 - 0.6 discriminant events\n",
    "data[\"Discriminants\"].plot(kind='hist', title = \"Discriminant in the Range [0.3, 0.5]\", bins = 100, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel Picture Script for [0.9, 1] discriminant testing events\n",
    "data = df_test [df_test[\"Discriminants\"] > 0.9 ] \n",
    "cluster_map(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 0.9 - 1 discriminant events\n",
    "data[\"Discriminants\"].plot(kind='hist' , title = \"Discriminant in the Range [0.9, 1]\", bins = 100, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Width and Length script\n",
    "\n",
    "# including all testing events\n",
    "data = df_test \n",
    "# sorting by discriminant ascending\n",
    "data = data.sort_values(\"Discriminants\", ascending = True)[0:len(data.index)-1]\n",
    "\n",
    "shareds =  data\n",
    "pixelColumns = [\"pixel_%i\" % x for x in range(36)]\n",
    "pixels = shareds[pixelColumns].values\n",
    "width = [] # dx\n",
    "length = [] # dy\n",
    "\n",
    "for row,hit,  in enumerate(pixels):\n",
    "    x_pos = []\n",
    "    y_pos = []\n",
    "    charge = []\n",
    "    arra = np.zeros((6,6))\n",
    "    for index,pixel in enumerate(hit):   \n",
    "        if pixel!=0:\n",
    "            x_pos.append(index%6)\n",
    "            y_pos.append(np.floor(index/6))  \n",
    "            charge.append(pixel)\n",
    "            arra [5 - int(np.floor(index/6))][int(index%6)]= pixel\n",
    "    \n",
    "    #Evaluating width and height of every event\n",
    "    charge_in_x = np.sum(arra,axis=0)\n",
    "    charge_in_y = np.sum(arra,axis=1)\n",
    "    charge_x_values = np.where(charge_in_x>0)[0]\n",
    "    charge_y_values = np.where(charge_in_y>0)[0]\n",
    "    wid = charge_x_values[-1] - charge_x_values[0] + 1\n",
    "    le = charge_y_values[-1] - charge_y_values[0] + 1\n",
    "    width.append(wid)\n",
    "    length.append(le)\n",
    "\n",
    " \n",
    " # Uncomment this section to display each event information and pixel pictures\n",
    "     # Event info\n",
    "#    text = \"Event \" + str(row +1) + \" with discriminant \" + str(np.around(data.iloc[row,0], decimals = 5)) + \", width \"+ str(wid)+ \" and length \" +str(le)\n",
    "#    print text\n",
    "#    # Plotting Colorbar  \n",
    "#    fig=plt.figure()\n",
    "#    ax=plt.axes()\n",
    "#    cax = plt.hist2d(x_pos,y_pos,weights=charge,bins=(6,6),range=((0,6),(0,6)))\n",
    "#    cb=fig.colorbar(cax[3])\n",
    "#    cb.set_ticks([0,max(charge)])\n",
    "#    cb.set_label(\"normalized adc\",rotation=-90)\n",
    "#\n",
    "#    # Title, uses truth value\n",
    "#    hits_column = df_test.columns.get_loc(\"nUniqueSimTracksInSharedHit\")\n",
    "#    if data.iloc[row,hits_column] == 1 : # 1 hit\n",
    "#        plt.title(\"Not Merged Cluster Charge Map\")\n",
    "#    elif data.iloc[row,hits_column] > 1 : # 2 or more hits\n",
    "#        plt.title(\"Merged Cluster Charge Map\")\n",
    "#    else : # 0 hits\n",
    "#        plt.title(\"Null Cluster Charge Map\")\n",
    "#    \n",
    "#    plt.xlabel(\"x\")\n",
    "#    plt.ylabel(\"y\")\n",
    "#    plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding width and height branch and checking they are there\n",
    "data.insert(1, \"Length\", length)\n",
    "data.insert(1, \"Width\", width)\n",
    "#print data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating signal and background for testing data\n",
    "signal = data[(data[\"nUniqueSimTracksInSharedHit\"]>1)]\n",
    "background = data[(data[\"nUniqueSimTracksInSharedHit\"]<2)]\n",
    "\n",
    "# Plotting CNN Signal and Background Width\n",
    "signal_plt_width = signal[\"Width\"]\n",
    "background_plt_width = background[\"Width\"]\n",
    "plt.hist(signal_plt_width, alpha = 0.5, color = 'b', label = 'Merged Hit', range = (1,6), bins = 6)\n",
    "plt.hist(background_plt_width, color = 'r', alpha = 0.5, label = 'Not Merged Hit', range = (1,6), bins = 6)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Merged vs Not Merged $\\Delta x$ in Testing Data')\n",
    "plt.xlabel('$\\Delta x$')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting CNN Signal and Background Height\n",
    "signal_plt_height = signal[\"Length\"]\n",
    "background_plt_height = background[\"Length\"]\n",
    "plt.hist(signal_plt_height, alpha = 0.5, color = 'b', label = 'Merged Hit', range = (1,6), bins = 6)\n",
    "plt.hist(background_plt_height, color = 'r', alpha = 0.5, label = 'Not Merged Hit', range = (1,6), bins = 6)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Merged vs Not Merged $\\Delta y$ in Testing Data')\n",
    "plt.xlabel('$\\Delta y$')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of Length vs Width in Testing for correlation in Merged Hits\n",
    "from scipy.stats.stats import pearsonr   \n",
    "x = signal_plt_width\n",
    "y = signal_plt_height  \n",
    "correlation = pearsonr(x,y)[0] \n",
    "plt.xlabel('$\\Delta x$')\n",
    "plt.ylabel('$\\Delta y$')\n",
    "plt.title('$\\Delta y$ vs $\\Delta x$ for Merged Hits in Testing') #(corr = {:.4f})'.format(correlation))\n",
    "plt.hist2d(x, y, (6, 6), cmap=plt.cm.Greys) # cmap=plt.cm.jet\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of Length vs Width in Testing for correlation in Not Merged Hits\n",
    "x = background_plt_width\n",
    "y = background_plt_height\n",
    "correlation = pearsonr(x,y)[0] \n",
    "plt.xlabel('$\\Delta x$')\n",
    "plt.ylabel('$\\Delta y$')\n",
    "plt.title('$\\Delta y$ vs $\\Delta x$ for Not Merged Hits in Testing') # (corr = {:.4f})'.format(correlation))\n",
    "plt.hist2d(x, y, (6, 6), cmap=plt.cm.Greys)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMS Width and RMS Length script\n",
    "\n",
    "# including all testing events\n",
    "data = df_test \n",
    "# sorting by discriminant ascending\n",
    "data = data.sort_values(\"Discriminants\", ascending = True)[0:len(data.index)-1]\n",
    "\n",
    "shareds =  data\n",
    "pixelColumns = [\"pixel_%i\" % x for x in range(36)]\n",
    "pixels = shareds[pixelColumns].values\n",
    "width = [] # dx\n",
    "length = [] # dy\n",
    "\n",
    "x_rms = []\n",
    "y_rms = []\n",
    "\n",
    "for row,hit,  in enumerate(pixels):\n",
    "    x_pos = []\n",
    "    y_pos = []\n",
    "    charge = []\n",
    "\n",
    "    arra = np.zeros((6,6))\n",
    "    for index,pixel in enumerate(hit):   \n",
    "        if pixel!=0:\n",
    "            x_pos.append(index%6)\n",
    "            y_pos.append(np.floor(index/6))  \n",
    "            charge.append(pixel)\n",
    "            arra [5 - int(np.floor(index/6))][int(index%6)]= pixel\n",
    "            \n",
    "    \n",
    "    #Evaluating width and height of every event\n",
    "    charge_in_x = np.sum(arra,axis=0)\n",
    "    charge_in_y = np.sum(arra,axis=1)\n",
    "    charge_x_values = np.where(charge_in_x>0)[0]\n",
    "    charge_y_values = np.where(charge_in_y>0)[0]\n",
    "    wid = charge_x_values[-1] - charge_x_values[0] + 1\n",
    "    le = charge_y_values[-1] - charge_y_values[0] + 1\n",
    "    width.append(wid)\n",
    "    length.append(le)\n",
    "    # x rms\n",
    "    mean_x = 0\n",
    "    x_ms = 0\n",
    "    for i in range (0,6):\n",
    "        mean_x = charge_in_x[i]*(i+1) + mean_x\n",
    "   # print mean_x\n",
    "    for i in range (0,6):\n",
    "        if charge_in_x[i] > 0:\n",
    "            x_ms = (mean_x - charge_in_x[i]*(i+1))**2 + x_ms\n",
    "    x_rms.append(np.sqrt(x_ms))\n",
    "    # y rms\n",
    "    mean_y = 0\n",
    "    y_ms = 0\n",
    "    for i in range (0,6):\n",
    "        mean_y = charge_in_y[i]*(i+1) + mean_y\n",
    "    # print mean_y\n",
    "    for i in range (0,6):\n",
    "        if charge_in_y[i] > 0:\n",
    "            y_ms = (mean_y - charge_in_y[i]*(i+1))**2 + y_ms\n",
    "    y_rms.append(np.sqrt(y_ms))\n",
    "    \n",
    " \n",
    " # Uncomment this section to display each event information and pixel pictures\n",
    "     # Event info\n",
    "#    text = \"Event \" + str(row +1) + \" with discriminant \" + str(np.around(data.iloc[row,0], decimals = 5)) + \", width \"+ str(wid)+ \" and length \" +str(le)\n",
    "#    print text\n",
    "#    # Plotting Colorbar  \n",
    "#    fig=plt.figure()\n",
    "#    ax=plt.axes()\n",
    "#    cax = plt.hist2d(x_pos,y_pos,weights=charge,bins=(6,6),range=((0,6),(0,6)))\n",
    "#    cb=fig.colorbar(cax[3])\n",
    "#    cb.set_ticks([0,max(charge)])\n",
    "#    cb.set_label(\"normalized adc\",rotation=-90)\n",
    "#\n",
    "#    # Title, uses truth value\n",
    "#    hits_column = df_test.columns.get_loc(\"nUniqueSimTracksInSharedHit\")\n",
    "#    if data.iloc[row,hits_column] == 1 : # 1 hit\n",
    "#        plt.title(\"Not Merged Cluster Charge Map\")\n",
    "#    elif data.iloc[row,hits_column] > 1 : # 2 or more hits\n",
    "#        plt.title(\"Merged Cluster Charge Map\")\n",
    "#    else : # 0 hits\n",
    "#        plt.title(\"Null Cluster Charge Map\")\n",
    "#    \n",
    "#    plt.xlabel(\"x\")\n",
    "#    plt.ylabel(\"y\")\n",
    "#    plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking at the flatten 2D maps either in x or y <br>\n",
    "pixelCharge is the pixel charge of the flattened 2D map, sum(pixelCharge) = 1  <br>\n",
    "pixelPos is the position of the flattened 2D maps pixel (range is 1 to 6)  <br>\n",
    "$\\overline{x} = \\sum_1^6 \\text{pixelCharge}^i \\ \\times \\ \\text{pixelPos}^i$  <br>\n",
    "$x^{RMS} = \\sqrt{  \\sum_1^6 (\\overline{x} - \\text{pixelPos}^i \\ \\times \\ \\text{pixelCharge}^i)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding width RMS and height RMS branch and checking they are there\n",
    "data.insert(1, \"Length RMS\", y_rms)\n",
    "data.insert(1, \"Width RMS\", x_rms)\n",
    "#print data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting CNN Signal and Background Width\n",
    "signal = data[(data[\"nUniqueSimTracksInSharedHit\"]>1)]\n",
    "background = data[(data[\"nUniqueSimTracksInSharedHit\"]<2)]\n",
    "signal_plt_width = signal[\"Width RMS\"]\n",
    "background_plt_width = background[\"Width RMS\"]\n",
    "plt.hist(signal_plt_width, alpha = 0.5, color = 'b', label = 'Merged Hit', range = (0,10), bins = 50)\n",
    "plt.hist(background_plt_width, color = 'r', alpha = 0.5, label = 'Not Merged Hit', range = (0,10), bins = 50)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Merged vs Not Merged $x^{RMS}$ in Testing Data')\n",
    "plt.xlabel('$x^{RMS}$')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(signal_plt_width, alpha = 0.5, color = 'b', label = 'Merged Hit', range = (2,4), bins = 8)\n",
    "plt.hist(background_plt_width, color = 'r', alpha = 0.5, label = 'Not Merged Hit', range = (2,4), bins = 8)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Merged vs Not Merged $x^{RMS}$ in Testing Data')\n",
    "plt.xlabel('$x^{RMS}$')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting CNN Signal and Background Height\n",
    "signal_plt_height = signal[\"Length RMS\"]\n",
    "background_plt_height = background[\"Length RMS\"]\n",
    "plt.hist(signal_plt_height, alpha = 0.5, color = 'b', label = 'Merged Hit', range = (0,10), bins = 50)\n",
    "plt.hist(background_plt_height, color = 'r', alpha = 0.5, label = 'Not Merged Hit', range = (0,10), bins = 50)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Merged vs Not Merged $y^{RMS}$ in Testing Data')\n",
    "plt.xlabel('$y^{RMS}$')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(signal_plt_height, alpha = 0.5, color = 'b', label = 'Merged Hit', range = (2,4), bins = 8)\n",
    "plt.hist(background_plt_height, color = 'r', alpha = 0.5, label = 'Not Merged Hit', range = (2,4), bins = 8)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Merged vs Not Merged $y^{RMS}$ in Testing Data')\n",
    "plt.xlabel('$y^{RMS}$')\n",
    "plt.ylabel('Reconstructed $\\Lambda$s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of Length vs Width in Testing for correlation in Merged Hits\n",
    "from scipy.stats.stats import pearsonr   \n",
    "x = signal_plt_width\n",
    "y = signal_plt_height  \n",
    "correlation = pearsonr(x,y)[0] \n",
    "plt.xlabel('$x^{RMS}$')\n",
    "plt.ylabel('$y^{RMS}$')\n",
    "plt.title('$y^{RMS}$ vs $x^{RMS}$ for Merged Hits in Testing') #(corr = {:.4f})'.format(correlation))\n",
    "plt.hist2d(x, y, (30, 30), cmap=plt.cm.jet) # cmap=plt.cm.Greys\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of Length vs Width in Testing for correlation in Not Merged Hits\n",
    "x = background_plt_width\n",
    "y = background_plt_height\n",
    "correlation = pearsonr(x,y)[0] \n",
    "plt.xlabel('$x^{RMS}$')\n",
    "plt.ylabel('$y^{RMS}$')\n",
    "plt.title('$y^{RMS}$ vs $x^{RMS}$ for Not Merged Hits in Testing') # (corr = {:.4f})'.format(correlation))\n",
    "plt.hist2d(x, y, (30, 30), cmap=plt.cm.jet) # cmap=plt.cm.Greys\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
