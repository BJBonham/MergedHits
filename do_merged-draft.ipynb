{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from IPython.display import FileLink, FileLinks\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines are not needed\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "cdir = os.getcwd()\n",
    "original = cdir + '/output_final.h5'\n",
    "target = cdir + '/output_final_copy.h5'\n",
    "\n",
    "if os.path.exists(target):\n",
    "    os.remove(target)\n",
    "else:\n",
    "    print(\"Can not delete the file as it doesn't exists\")\n",
    "\n",
    "shutil.copyfile(original,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 image has 6x6 pixels = 36 pixels \n",
    "###################### Need to try 16 x 16 and 8 x 8 and see the effect (making a heatmap for 3,4 hits), can be changed in Convertroototpand.py\n",
    "pixels = [\"pixel_{0}\".format(i) for i in range(36)]\n",
    "def to_image(df):\n",
    "    return  np.expand_dims(np.expand_dims(df[pixels], axis=-1).reshape(-1,6,6), axis=-1)\n",
    "\n",
    "\n",
    "# You need to email hichemb@princeton.edu to request access to this directory, or else this line will not work\n",
    "pandas.read_hdf(\"/eos/user/h/hboucham/SWAN_projects/MergedHits/output_final.h5\",mode='r')\n",
    "# replace this sample every time you train CNN\n",
    "#store_train = pandas.HDFStore(\"output_final_copy.h5\")\n",
    "\n",
    "# kinda like tree1\n",
    "df = store_train.select(\"df\",stop=-1) \n",
    "\n",
    "#cut on DeltaR and nUniqueSimTracksInSharedHit\n",
    "##################################################### Need to move this to ConvertRoottoPanda.py\n",
    "df = df[(df[\"GenDeltaR\"]<0.1) & (df[\"nUniqueSimTracksInSharedHit\"]>-1)]\n",
    "#images_train = to_image(df_train)\n",
    "\n",
    "\n",
    "# Don't need these since I'm using the same files and splitting it, might be useful if I'm using a training file and a testing file\n",
    "#store_test = pandas.HDFStore(\"pixelTrain30k.h5\") #######\n",
    "#df_test = store_test.select(\"df\",stop=-1)\n",
    "#df_test = df_test[(df_test[\"GenDeltaR\"]<0.1) & (df_test[\"nUniqueSimTracksInSharedHit\"]>-1)]0 if shared hit but not merged, -1 if neither, 1, 2,3 if sahred and merged\n",
    "#images_test = to_image(df_test)\n",
    "#comb = pandas.concat([df_train,df_test])\n",
    "#df_train=comb.sample(frac=0.6) ######\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#***************************************************** Jack's notebook: only include shared hits so 0 events are not included here !\n",
    "# Make all test, train data merged hit\n",
    "#df_test = df_test[(df_test[\"isSharedHit\"]>0)]\n",
    "#df_train = df_train[(df_train[\"isSharedHit\"]>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Throwing away events that have single pixel since the neural network cannot tell whether it's merged or not, there is simply not enough information.\n",
    "pixelColumns = [\"pixel_%i\" % x for x in range(36)]\n",
    "pixels_df = df[pixelColumns].values\n",
    "print(pixels_df[0].shape)\n",
    "pixel_number = pixels_df.astype(bool).sum(axis=1)\n",
    "df.insert(0, \"Pixel_number\", pixel_number)\n",
    "print df.info()\n",
    "df = df[df[\"Pixel_number\"]>1]\n",
    "print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frac=0.5 sets half training and half testing\n",
    "df_train=df.sample(frac=0.5)\n",
    "df_test=df.drop(df_train.index)\n",
    "images_train = to_image(df_train)\n",
    "images_test = to_image(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: printout (events, variables) Variables include 36 pixels, and a few others you can find in converroottopands.py\n",
    "print df_test.shape\n",
    "print df_train.shape\n",
    "print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('training.txt', separator=\",\", append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the CNN\n",
    "# Adding layers to Neural Network: (1) is convolutional,(1.5) 2D layer ,(2) flatten output then feed it to (3) which is a regular neural network.\n",
    "# (4) drops nodes in NN to avoid overfitting, finallly (5) outputs 2 values (prob(notmergedhit), prob(merged hit)), should add up to 1\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "# Define the network\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#layer (1)\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(4,4), padding='same', activation='relu'))\n",
    "\n",
    "#layer (1.5)\n",
    "############################################## 2D layers: need to add these back individually and see their effect\n",
    "#********************************************# what does this layer do again ?\n",
    "#model.add(keras.layers.Conv2D(16, kernel_size=(4,4), padding='same', activation='relu'))\n",
    "#model.add(keras.layers.Conv2D(16, kernel_size=(2,2), padding='same', activation='relu'))\n",
    "#model.add(keras.layers.Conv2D(16, kernel_size=(1,1), padding='same', activation='relu'))\n",
    "\n",
    "# max pooling 2D\n",
    "#model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same', data_format=\"channels_last\"))\n",
    "\n",
    "# layer (2)\n",
    "model.add(keras.layers.Flatten(input_shape=(6,6,1),data_format = \"channels_last\"))\n",
    "#model.add(keras.layers.Dense(200, activation='relu'))\n",
    "\n",
    "# layer (3)\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "\n",
    "# layer 4, dropout 10%\n",
    "model.add(Dropout(0.1))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "#print(model.summary())\n",
    "                                                    \n",
    "# Layer (5), train the network\n",
    "###############################################################  try to find a way to include pt, eta, phi after first layer (convolutional)\n",
    "# optimal number of epochs, var name might be model.loss.\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics = [\"accuracy\"]) \n",
    "model.fit(images_train, keras.utils.to_categorical(df_train[\"nUniqueSimTracksInSharedHit\"]>1), callbacks=[csv_logger], epochs=100, validation_split=0.1) \n",
    "# validation fraction is fraction of training sample used for testing (here 10%), epochs: number of times you run the CNN.\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS(EPOCH) PLOT\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import truediv\n",
    "\n",
    "loss = []\n",
    "\n",
    "with open(\"training.txt\" )  as file:\n",
    "     for line in file:\n",
    "           # print(line)\n",
    "            n = line.find(\"epoch\")\n",
    "            if n != -1:\n",
    "                continue\n",
    "            n = line.find(\",\",6, len(line)-1)\n",
    "            if n != -1:\n",
    "                x = line[n+1:n+ 7]\n",
    "                #print(x)\n",
    "                #print (type(x))\n",
    "                x = float(x)\n",
    "                loss.append(x)\n",
    "                continue\n",
    "print(loss)\n",
    "\n",
    "epoch = []\n",
    "for i in range(0,100): # 100 epoch number\n",
    "    epoch.append(float(i+1))\n",
    "    \n",
    "print(epoch)\n",
    "\n",
    "ratio = []\n",
    "for i in range(0,100): # epoch number\n",
    "    #r = loss/epoch\n",
    "    r = map(truediv, loss, epoch)\n",
    "#    r = round(r,5)\n",
    "    ratio.append(r)\n",
    "    \n",
    "#print(ratio)\n",
    "p = np.poly1d(np.polyfit(epoch, loss, 10)) # find the right fit please\n",
    "t = np.linspace(1,100, 2000) # remember to change 100 to epoch number and 2000 scales with epochs as well\n",
    "plt.plot(epoch, loss, 'o', t, p(t),  '-')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epoch plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate performance on independent sample, un CNN on Test sample\n",
    "print(\"Running on full test sample. This may take a moment.\")\n",
    "ret = model.predict(images_test)\n",
    "np.save(\"result.pynb\",ret[:,1]) #this line doesn't work\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating ROC curve inputs\n",
    "from sklearn.metrics import roc_curve\n",
    "#fpr_keras, tpr_keras, thresholds_keras = roc_curve(keras.utils.to_categorical(df_test[\"isSharedHit\"])[:,1], ret[:,1])\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(keras.utils.to_categorical(df_test[\"nUniqueSimTracksInSharedHit\"]>1)[:,1], ret[:,1])\n",
    "\n",
    "print fpr_keras,tpr_keras\n",
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "print auc_keras\n",
    "print np.isnan(fpr_keras).all()\n",
    "print len(fpr_keras),len(tpr_keras)\n",
    "np.save(\"fpr_keras.npy\",fpr_keras)\n",
    "np.save(\"tpr_keras.npy\",tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting ROC curve\n",
    "\n",
    "fpr_keras = np.load(\"fpr_keras.npy\")\n",
    "tpr_keras = np.load(\"tpr_keras.npy\")\n",
    "auc = np.trapz(tpr_keras,fpr_keras)\n",
    "print auc\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (area = {:.3f})'.format(auc))\n",
    "plt.savefig(\"ROC.png\")\n",
    "plt.savefig(\"ROC.pdf\")\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: no overlap between train and test \n",
    "pandas.merge(df_train, df_test, on=[x for x in df_train.columns], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing our data\n",
    "print \"shared hits with at least 2 sim tracks:\"\n",
    "print float(sum(df_train[\"nUniqueSimTracksInSharedHit\"]>1))/len(df_train[\"nUniqueSimTracksInSharedHit\"])\n",
    "plt.hist(df_train[\"nUniqueSimTracksInSharedHit\"],histtype=\"step\",bins=6,range=(-0.5,5.5))\n",
    "plt.xlabel('Hits')\n",
    "plt.ylabel('Events')\n",
    "plt.title(\"Distribution of Hits in Training Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing merged (2 or more) vs not merged (1 or 0 (?)) \n",
    "################################################################ Look at events with nUniqueSimTracksInSharedHit = 0(seem to be uncategorized ?)\n",
    "print float(sum(df_train[\"nUniqueSimTracksInSharedHit\"]>1))/len(df_train[\"nUniqueSimTracksInSharedHit\"])\n",
    "plt.hist(df_train[\"nUniqueSimTracksInSharedHit\"]>1,histtype=\"step\",bins=2,range=(-0.5,1.5))\n",
    "plt.title(\"Distribution of Hits in Training Data\")\n",
    "plt.xticks([0,1],(\"Not Merged\",\"Merged\"))\n",
    "plt.ylabel('Events')\n",
    "plt.savefig(\"merged_dist.png\")\n",
    "plt.savefig(\"merged_dist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating signal and background for train and test data\n",
    "signal = ret[df_test[\"nUniqueSimTracksInSharedHit\"]>1]\n",
    "background = ret[df_test[\"nUniqueSimTracksInSharedHit\"]<2]\n",
    "\n",
    "signal_plt = signal[:,1]\n",
    "background_plt = background[:,1]\n",
    "\n",
    "ret_train = model.predict(images_train)\n",
    "\n",
    "signal_train = ret_train[df_train[\"nUniqueSimTracksInSharedHit\"]>1]\n",
    "background_train = ret_train[df_train[\"nUniqueSimTracksInSharedHit\"]<2]\n",
    "signal_train_plt = signal_train[:,1]\n",
    "background_train_plt = background_train[:,1]\n",
    "\n",
    "Y_back_hist = np.histogram(background_train_plt, bins = 30, range = (0,1))[0]\n",
    "X_back_hist = np.histogram(background_train_plt, bins = 30, range = (0,1))[1]\n",
    "\n",
    "Y_sig_hist = np.histogram(signal_train_plt, bins = 30, range = (0,1))[0]\n",
    "X_sig_hist = np.histogram(signal_train_plt, bins = 30, range = (0,1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Signal and background plot \n",
    "plt.hist(signal_plt, alpha = 0.5, color = 'b', label = 'Signal (test)', range = (0,1), bins = 30)\n",
    "plt.hist(background_plt, color = 'r', alpha = 0.5, label = 'Background (test)', range = (0,1), bins = 30)\n",
    "plt.scatter(X_back_hist[0:30] + 0.0166 , Y_back_hist, label='Background (train)', color ='r')\n",
    "plt.scatter(X_sig_hist[0:30] + 0.0166, Y_sig_hist, label='Signal (train)', color='b')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Discriminant')\n",
    "plt.ylabel('Events')\n",
    "plt.title('CNN Signal and Background Discriminants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ret_train > .46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df_train[ret_train[:,1]>.46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df_train[(ret_train[:,1]>.46) & (ret_train[:,1]<.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding isMergedHit column , not necessary\n",
    "############# DO NOT RUN THIS !!! #############################\n",
    "\n",
    "# for train\n",
    "#merged_hit = df_train[\"nUniqueSimTracksInSharedHit\"]>1\n",
    "#merged_int = merged_hit.astype(int)\n",
    "#df_train.insert(0, \"isMergedHit\", merged_int, True)\n",
    "\n",
    "# for test\n",
    "#merged_hit_test = df_test[\"nUniqueSimTracksInSharedHit\"]>1\n",
    "#merged_int_test = merged_hit_test.astype(int)\n",
    "#df_test.insert(0, \"isMergedHit\", merged_int_test, True)\n",
    "\n",
    "#df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Discriminant branch to df_test only for now\n",
    "\n",
    "index = df_test.index\n",
    "N = len(index)\n",
    "print N\n",
    "\n",
    "\n",
    "temp = []\n",
    "discriminants_test = model.predict(images_test)\n",
    "for i in range (0,N):\n",
    "   # print determinant_train[i][0]\n",
    "    temp.append(discriminants_test[i][1])\n",
    "\n",
    "#print (temp)\n",
    "df_test.insert(0, \"Discriminants\", temp)\n",
    "\n",
    "#determinant_test = model.predict(images_test)\n",
    "#print (determinant_test[1][0])\n",
    "#df_test.insert(0, \"Determinant (sig)\", determinant_test)\n",
    "#df_test.insert(0, \"Determinant\", determinant, True)\n",
    "#df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printout\n",
    "print df_test [(df_test[\"Discriminants\"] > 0.3 ) & (df_test[\"Discriminants\"] < 0.5 ) ] [\"Discriminants\"]\n",
    "#df_train.keys, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df_test.columns.get_loc(\"nUniqueSimTracksInSharedHit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure column 21 is \"nUniqueSimTracksInSharedHit\"\n",
    "for i in range(0,5000):\n",
    "    if df_test.iloc[i,22] == 0:\n",
    "        print df_test.iloc[i,22]\n",
    "\n",
    "print df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIXEL PICTURE SCRIPT 0.3 - 0.5 discriminant events, Looking at df test pixels only for now\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#data = pd.read_hdf('pixelTrain30k.h5')\n",
    "#data = pd.read_hdf('output_final_copy.h5')\n",
    "data = df_test [(df_test[\"Discriminants\"] > 0.3 ) & (df_test[\"Discriminants\"] < 0.5 ) ]\n",
    "\n",
    "hits_column = df_test.columns.get_loc(\"nUniqueSimTracksInSharedHit\")\n",
    "\n",
    "index = data.index\n",
    "N = len(index)\n",
    "print N\n",
    "#print data.info()\n",
    "\n",
    "# sorting by discriminant ascending\n",
    "data = data.sort_values(\"Discriminants\", ascending = True)[0:len(data.index)-1]\n",
    "# shareds = data[data[\"nUniqueSimTracksInSharedHit\"]==1]\n",
    "shareds =  data\n",
    "\n",
    "\n",
    "#shareds.sort_values(\"Discriminants\", ascending = True)\n",
    "# (ret_train[:,1]>.46) & (ret_train[:,1]<.5) & there\n",
    "#pixels = shareds[(shareds.columns[6:])].values\n",
    "\n",
    "pixelColumns = [\"pixel_%i\" % x for x in range(36)]\n",
    "pixels = shareds[pixelColumns].values\n",
    "print(pixels[0].shape)\n",
    "\n",
    "#print(pixels[0].shape)\n",
    "\n",
    "index = shareds.index\n",
    "N = len(index)\n",
    "print N\n",
    "\n",
    "# condidtional here if (ret_train[:,1]>.46) & (ret_train[:,1]<.5):\n",
    "for row,hit,  in enumerate(pixels):\n",
    "    x_pos = []\n",
    "    y_pos = []\n",
    "    charge = []\n",
    "    for index,pixel in enumerate(hit):\n",
    "        if pixel!=0:\n",
    "            x_pos.append(index%6)\n",
    "            y_pos.append(np.floor(index/6))  \n",
    "            charge.append(pixel)\n",
    "    #print(row, ret_train[row][0]) ######################### this should be discriminant number ? ret\n",
    "    print(row, data.iloc[row,0] )\n",
    "        \n",
    "    fig=plt.figure()\n",
    "    ax=plt.axes()\n",
    "    cax = plt.hist2d(x_pos,y_pos,weights=charge,bins=(6,6),range=((0,6),(0,6)))\n",
    "    cb=fig.colorbar(cax[3])\n",
    "    cb.set_ticks([0,max(charge)])\n",
    "    cb.set_label(\"normalized adc\",rotation=-90)\n",
    "\n",
    "    \n",
    "    # Title, note that 21 refers to the columns position of the column nUniqueSimTracksInSharedHit\n",
    "    hits_column = df_test.columns.get_loc(\"nUniqueSimTracksInSharedHit\")\n",
    "    if data.iloc[row,hits_column] == 1 : # 1 hit\n",
    "        plt.title(\"Not Merged Cluster Charge Map\")\n",
    "    elif data.iloc[row,hits_column] > 1 : # 2 or more hits\n",
    "        plt.title(\"Merged Cluster Charge Map\")\n",
    "    else : # 0 hits\n",
    "        plt.title(\"Null Cluster Charge Map\")\n",
    "    \n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "   \n",
    "    # uncomment below to save plots\n",
    "    #plt.savefig(str(row)+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 0.3 - 0.5 discriminant events\n",
    "data[\"Discriminants\"].plot(kind='hist', title = \"Discriminant in the range [0.3, 0.5]\", bins = 100, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIXEL PICTURE SCRIPT 0.9 - 1 discriminant events, Looking at df test pixels only for now\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#data = pd.read_hdf('pixelTrain30k.h5')\n",
    "#data = pd.read_hdf('output_final_copy.h5')\n",
    "data = df_test [df_test[\"Discriminants\"] > 0.9 ]\n",
    "\n",
    "index = data.index\n",
    "N = len(index)\n",
    "print N\n",
    "#print data.info()\n",
    "\n",
    "# sorting by discriminant ascending\n",
    "data = data.sort_values(\"Discriminants\", ascending = True)[0:len(data.index)-1]\n",
    "# shareds = data[data[\"nUniqueSimTracksInSharedHit\"]==1]\n",
    "shareds =  data\n",
    "\n",
    "\n",
    "#shareds.sort_values(\"Discriminants\", ascending = True)\n",
    "# (ret_train[:,1]>.46) & (ret_train[:,1]<.5) & there\n",
    "#pixels = shareds[(shareds.columns[6:])].values ###### add the 2 lines\n",
    "\n",
    "pixelColumns = [\"pixel_%i\" % x for x in range(36)]\n",
    "pixels = shareds[pixelColumns].values\n",
    "print(pixels[0].shape)\n",
    "\n",
    "index = shareds.index\n",
    "N = len(index)\n",
    "print N\n",
    "\n",
    "# condidtional here if (ret_train[:,1]>.46) & (ret_train[:,1]<.5):\n",
    "for row,hit,  in enumerate(pixels):\n",
    "    x_pos = []\n",
    "    y_pos = []\n",
    "    charge = []\n",
    "    for index,pixel in enumerate(hit):\n",
    "        if pixel!=0:\n",
    "            x_pos.append(index%6)\n",
    "            y_pos.append(np.floor(index/6))  \n",
    "            charge.append(pixel)\n",
    "    #print(row, ret_train[row][0]) \n",
    "    print(row, data.iloc[row,0] ) # row refers to event number, 0 refers to column 0, which is the \"Discriminants\" column\n",
    "        \n",
    "    fig=plt.figure()\n",
    "    ax=plt.axes()\n",
    "    cax = plt.hist2d(x_pos,y_pos,weights=charge,bins=(6,6),range=((0,6),(0,6)))\n",
    "    cb=fig.colorbar(cax[3])\n",
    "    cb.set_ticks([0,max(charge)])\n",
    "    cb.set_label(\"normalized adc\",rotation=-90)\n",
    " \n",
    "    # Title, note that 22 refers to the columns position of the column \"nUniqueSimTracksInSharedHit\"\n",
    "    hits_column = df_test.columns.get_loc(\"nUniqueSimTracksInSharedHit\")\n",
    "    if data.iloc[row,hits_column] == 1 : # 1 hit\n",
    "        plt.title(\"Not Merged Cluster Charge Map\")\n",
    "    elif data.iloc[row,hits_column] > 1 : # 2 or more hits\n",
    "        plt.title(\"Merged Cluster Charge Map\")\n",
    "    else : # 0 hits\n",
    "        plt.title(\"Null Cluster Charge Map\")\n",
    "    \n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "   \n",
    "    # uncomment below to save plots\n",
    "    #plt.savefig(str(row)+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 0.9 - 1 discriminant events\n",
    "data[\"Discriminants\"].plot(kind='hist' , title = \"Discriminant in the range [0.9, 1]\", bins = 100, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIXEL PICTURE SCRIPT 0 - 0.1 discriminant events, Looking at df test pixels only for now\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#data = pd.read_hdf('pixelTrain30k.h5')\n",
    "#data = pd.read_hdf('output_final_copy.h5')\n",
    "data = df_test [(df_test[\"Discriminants\"] < 0.1 )]\n",
    "\n",
    "index = data.index\n",
    "N = len(index)\n",
    "print N\n",
    "#print data.info()\n",
    "\n",
    "# sorting by discriminant ascending\n",
    "data = data.sort_values(\"Discriminants\", ascending = True)[0:len(data.index)-1]\n",
    "# shareds = data[data[\"nUniqueSimTracksInSharedHit\"]==1]\n",
    "shareds =  data\n",
    "\n",
    "\n",
    "shareds.sort_values(\"Discriminants\", ascending = True)\n",
    "# (ret_train[:,1]>.46) & (ret_train[:,1]<.5) & there\n",
    "#pixels = shareds[(shareds.columns[6:])].values\n",
    "\n",
    "pixelColumns = [\"pixel_%i\" % x for x in range(36)]\n",
    "pixels = shareds[pixelColumns].values\n",
    "print(pixels[0].shape)\n",
    "\n",
    "index = shareds.index\n",
    "N = len(index)\n",
    "print N\n",
    "\n",
    "# condidtional here if (ret_train[:,1]>.46) & (ret_train[:,1]<.5):\n",
    "for row,hit,  in enumerate(pixels):\n",
    "    x_pos = []\n",
    "    y_pos = []\n",
    "    charge = []\n",
    "    for index,pixel in enumerate(hit):\n",
    "        if pixel!=0:\n",
    "            x_pos.append(index%6)\n",
    "            y_pos.append(np.floor(index/6))  \n",
    "            charge.append(pixel)\n",
    "    #print(row, ret_train[row][0]) ######################### this should be discriminant number ? ret\n",
    "    print(row, data.iloc[row,0] )\n",
    "        \n",
    "    fig=plt.figure()\n",
    "    ax=plt.axes()\n",
    "    cax = plt.hist2d(x_pos,y_pos,weights=charge,bins=(6,6),range=((0,6),(0,6)))\n",
    "    cb=fig.colorbar(cax[3])\n",
    "    cb.set_ticks([0,max(charge)])\n",
    "    cb.set_label(\"normalized adc\",rotation=-90)\n",
    " \n",
    "    # Title, note that 22 refers to the columns position of the column nUniqueSimTracksInSharedHit\n",
    "    hits_column = df_test.columns.get_loc(\"nUniqueSimTracksInSharedHit\")\n",
    "    if data.iloc[row,hits_column] == 1 : # 1 hit\n",
    "        plt.title(\"Not Merged Cluster Charge Map\")\n",
    "    elif data.iloc[row,hits_column] > 1 : # 2 or more hits\n",
    "        plt.title(\"Merged Cluster Charge Map\")\n",
    "    else : # 0 hits\n",
    "        plt.title(\"Null Cluster Charge Map\")\n",
    "    \n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "   \n",
    "    # uncomment below to save plots\n",
    "    #plt.savefig(str(row)+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 0 - 0.1 discriminant events\n",
    "data[\"Discriminants\"].plot(kind='hist', title = \"Discriminant in the range [0, 0.1]\", bins = 100, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIDTH + HEIGHT SCRIPT\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#data = pd.read_hdf('pixelTrain30k.h5')\n",
    "#data = pd.read_hdf('output_final_copy.h5')\n",
    "data = df_test \n",
    "\n",
    "index = data.index\n",
    "N = len(index)\n",
    "print N\n",
    "#print data.info()\n",
    "\n",
    "# sorting by discriminant ascending\n",
    "data = data.sort_values(\"Discriminants\", ascending = True)[0:len(data.index)-1]\n",
    "# shareds = data[data[\"nUniqueSimTracksInSharedHit\"]==1]\n",
    "shareds =  data\n",
    "\n",
    "\n",
    "#shareds.sort_values(\"Discriminants\", ascending = True)\n",
    "# (ret_train[:,1]>.46) & (ret_train[:,1]<.5) & there\n",
    "#pixels = shareds[(shareds.columns[6:])].values\n",
    "\n",
    "pixelColumns = [\"pixel_%i\" % x for x in range(36)]\n",
    "pixels = shareds[pixelColumns].values\n",
    "\n",
    "print(pixels[0].shape)\n",
    "\n",
    "\n",
    "index = shareds.index\n",
    "N = len(index)\n",
    "print N\n",
    "\n",
    "width = [] # dx\n",
    "height = [] # dy\n",
    "# condidtional here if (ret_train[:,1]>.46) & (ret_train[:,1]<.5):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for row,hit,  in enumerate(pixels):\n",
    "    x_pos = []\n",
    "    y_pos = []\n",
    "    charge = []\n",
    "    #init the array\n",
    "    arra = np.zeros((6,6))\n",
    "    #ro, co = (6, 6) \n",
    "    #arra = [[0]*co]*ro \n",
    "    #print(arra)\n",
    "    for index,pixel in enumerate(hit):   \n",
    "        if pixel!=0:\n",
    "            x_pos.append(index%6)\n",
    "            y_pos.append(np.floor(index/6))  \n",
    "            charge.append(pixel)\n",
    "            #print (index%6, np.floor(index/6), pixel)\n",
    "            arra [5 - int(np.floor(index/6))][int(index%6)]= pixel\n",
    "    \n",
    "    print arra\n",
    "    charge_in_x = np.sum(arra,axis=0)\n",
    "    charge_in_y = np.sum(arra,axis=1)\n",
    "    #print charge_in_x\n",
    "    charge_x_values = np.where(charge_in_x>0)[0]\n",
    "    charge_y_values = np.where(charge_in_y>0)[0]\n",
    "    #print charge_x_values\n",
    "    wid = charge_x_values[-1] - charge_x_values[0] + 1\n",
    "    hei = charge_y_values[-1] - charge_y_values[0] + 1\n",
    "    width.append(wid)\n",
    "    height.append(hei)\n",
    "    #print(row, ret_train[row][0]) ######################### this should be discriminant number ? ret\n",
    "    print(row, np.around(data.iloc[row,0], decimals= 5), wid, hei )\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing single pixel \n",
    "\n",
    "#pixel_number = np.sum(pixels[np.sum(pixels>0,axis=1)==1], axis = 1)\n",
    "#print pixel_number\n",
    "\n",
    "pixel_number = pixels.astype(bool).sum(axis=1)\n",
    "#print len(pixel_number)\n",
    "#print len(data)\n",
    "#data.insert(1, \"Pixel_number\", pixel_number)\n",
    "print data.info()\n",
    "data_new = data[data[\"Pixel_number\"]>1]\n",
    "print data_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding height and width branch\n",
    "data.insert(1, \"Height\", height)\n",
    "data.insert(1, \"Width\", width)\n",
    "print data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating signal and background for train and test data\n",
    "signal = data[(data[\"nUniqueSimTracksInSharedHit\"]>1)]\n",
    "background = data[(data[\"nUniqueSimTracksInSharedHit\"]<2)]\n",
    "\n",
    "signal_plt_width = signal[\"Width\"]\n",
    "background_plt_width = background[\"Width\"]\n",
    "\n",
    "#ret_train = model.predict(images_train)\n",
    "\n",
    "#signal_train = ret_train[df_train[\"nUniqueSimTracksInSharedHit\"]>1]\n",
    "#background_train = ret_train[df_train[\"nUniqueSimTracksInSharedHit\"]<2]\n",
    "#signal_train_plt = signal_train[:,1]\n",
    "#background_train_plt = background_train[:,1]\n",
    "\n",
    "#Y_back_hist = np.histogram(background_train_plt, bins = 30, range = (0,1))[0]\n",
    "#X_back_hist = np.histogram(background_train_plt, bins = 30, range = (0,1))[1]\n",
    "\n",
    "#Y_sig_hist = np.histogram(signal_train_plt, bins = 30, range = (0,1))[0]\n",
    "#X_sig_hist = np.histogram(signal_train_plt, bins = 30, range = (0,1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Signal and background plot # hist type = ste[]\n",
    "plt.hist(signal_plt_width, alpha = 0.5, color = 'b', label = 'Signal (test)', range = (1,6), bins = 6)\n",
    "plt.hist(background_plt_width, color = 'r', alpha = 0.5, label = 'Background (test)', range = (1,6), bins = 6)\n",
    "#plt.scatter(X_back_hist[0:30] + 0.0166 , Y_back_hist, label='Background (train)', color ='r')\n",
    "#plt.scatter(X_sig_hist[0:30] + 0.0166, Y_sig_hist, label='Signal (train)', color='b')\n",
    "plt.legend(loc='best')\n",
    "plt.title('CNN Signal and Background Width')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal = data[(data[\"nUniqueSimTracksInSharedHit\"]>1)]\n",
    "#background = data[(data[\"nUniqueSimTracksInSharedHit\"]<2)]\n",
    "\n",
    "signal_plt_height = signal[\"Height\"]\n",
    "background_plt_height = background[\"Height\"]\n",
    "\n",
    "plt.hist(signal_plt_height, alpha = 0.5, color = 'b', label = 'Signal (test)', range = (1,6), bins = 6)\n",
    "plt.hist(background_plt_height, color = 'r', alpha = 0.5, label = 'Background (test)', range = (1,6), bins = 6)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.title('CNN Signal and Background Height')\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
